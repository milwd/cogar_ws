

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Subsystem Interaction &mdash; cogar_ass1 1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="_static/graphviz.css?v=4ae1632d" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=f2a433a1"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Voice Recognition" href="interaction_modules/voice_recognition.html" />
    <link rel="prev" title="Force Sensor" href="control_modules/force.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            cogar_ass1
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="vision.html">Subsystem Vision</a></li>
<li class="toctree-l1"><a class="reference internal" href="brain.html">Subsystem Brain</a></li>
<li class="toctree-l1"><a class="reference internal" href="navigation.html">Subsystem Navigation</a></li>
<li class="toctree-l1"><a class="reference internal" href="control.html">Subsystem Control</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Subsystem Interaction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#what-the-interaction-subsystem-does">What the Interaction subsystem does</a></li>
<li class="toctree-l2"><a class="reference internal" href="#design-patterns">Design Patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#observer">Observer</a></li>
<li class="toctree-l3"><a class="reference internal" href="#adapter">Adapter</a></li>
<li class="toctree-l3"><a class="reference internal" href="#strategy">Strategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#template-method">Template Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="#command">Command</a></li>
<li class="toctree-l3"><a class="reference internal" href="#chain-of-responsibility">Chain of Responsibility</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#component-roles">Component roles</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ros-interfaces-kpis">ROS interfaces &amp; KPIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="#implementation-modules">Implementation modules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="interaction_modules/voice_recognition.html">Voice Recognition</a></li>
<li class="toctree-l3"><a class="reference internal" href="interaction_modules/microphone.html">Microphone</a></li>
<li class="toctree-l3"><a class="reference internal" href="interaction_modules/reasoning_order_verification.html">Reasoning Order Verification</a></li>
<li class="toctree-l3"><a class="reference internal" href="interaction_modules/speaker.html">Speaker</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="server.html">Subsystem Server</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">cogar_ass1</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Subsystem Interaction</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/interaction.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="subsystem-interaction">
<h1>Subsystem Interaction<a class="headerlink" href="#subsystem-interaction" title="Link to this heading"></a></h1>
<section id="what-the-interaction-subsystem-does">
<h2>What the Interaction subsystem does<a class="headerlink" href="#what-the-interaction-subsystem-does" title="Link to this heading"></a></h2>
<p>The Interaction layer is responsible for all spoken I/O between customers and the TIAGo fleet:</p>
<ol class="arabic simple">
<li><p><strong>Capture</strong> raw audio events (or simulate them) from microphones.</p></li>
<li><p><strong>Recognise</strong> spoken commands, converting integer “utterances” into plain‐text.</p></li>
<li><p><strong>Validate</strong> customer orders (“Can I have …”) before they enter the task queue, catching missing requests or unknown dishes.</p></li>
<li><p><strong>Announce</strong> robot status and customer notifications in a human‐friendly, rate‐controlled fashion.</p></li>
</ol>
<a class="reference internal image-reference" href="_images/interaction_subsystem.png"><img alt="Component diagram of the Interaction subsystem" class="align-center" src="_images/interaction_subsystem.png" style="width: 90%;" />
</a>
</section>
<section id="design-patterns">
<h2>Design Patterns<a class="headerlink" href="#design-patterns" title="Link to this heading"></a></h2>
<section id="observer">
<h3>Observer<a class="headerlink" href="#observer" title="Link to this heading"></a></h3>
<p><strong>voice_recognition.py</strong> and <strong>speaker.py</strong> both subscribe to topics (mic_channel or speaker_channel) and process each incoming message as soon as it arrives.  This push‐based design eliminates polling and guarantees each event is handled exactly once, keeping latency low and resource usage efficient.</p>
</section>
<section id="adapter">
<h3>Adapter<a class="headerlink" href="#adapter" title="Link to this heading"></a></h3>
<p><strong>voice_recognition.py</strong> implements a dictionary‐based adapter that maps raw <cite>Int32</cite> codes into natural‐language sentences.  By centralising this mapping, the downstream order verification node never sees numeric keys—only human‐readable text—keeping the ASR stub and the verification logic cleanly separated.</p>
</section>
<section id="strategy">
<h3>Strategy<a class="headerlink" href="#strategy" title="Link to this heading"></a></h3>
<p><strong>reasoning_order_verification.py</strong> uses a simple substring‐match strategy to detect the “Can I have” fragment and a list‐matching strategy for dish recognition.  In the future we could swap in a more sophisticated NLP strategy (e.g. regex‐based, ML‐based entity extraction) without changing the orchestration of parse → validate → publish.</p>
</section>
<section id="template-method">
<h3>Template Method<a class="headerlink" href="#template-method" title="Link to this heading"></a></h3>
<p><strong>speech_generator.py</strong> implements a fixed two‐step loop—<strong>cache</strong> incoming text, then <strong>publish</strong> it at 1 Hz—while allowing customization of caching or republishing hooks.  To introduce context‐aware gating or dynamic rate adaptation, we override only those hook methods, not the entire republishing flow.</p>
</section>
<section id="command">
<h3>Command<a class="headerlink" href="#command" title="Link to this heading"></a></h3>
<p><strong>reasoning_order_verification.py</strong> wraps validated orders in a <cite>tiago1/Voice_rec</cite> message and also constructs a <cite>send_orderRequest</cite> for the <cite>/robot_state_decision_add</cite> service.  Both the publish and service‐call act like commands that can be retried, queued or extended, decoupling the verification logic from the rest of the orchestration.</p>
</section>
<section id="chain-of-responsibility">
<h3>Chain of Responsibility<a class="headerlink" href="#chain-of-responsibility" title="Link to this heading"></a></h3>
<p>In <strong>reasoning_order_verification.py</strong>, the <cite>parse_order()</cite> method applies a sequence of checks—polite‐request guard, dish‐matching guard, then structured message creation or error emission.  We can insert additional validation steps (e.g. profanity filter, multi‐language support) simply by adding new handlers to this chain without rewriting existing logic.</p>
</section>
</section>
<section id="component-roles">
<h2>Component roles<a class="headerlink" href="#component-roles" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><strong>microphone.py</strong>
- Publishes a random or real <cite>std_msgs/Int32</cite> on <cite>/&lt;robot&gt;/mic_channel</cite> to emulate microphone events at 1 Hz.</p></li>
<li><p><strong>voice_recognition.py</strong>
- Subscribes to <cite>/mic_channel</cite>, maps each <cite>Int32</cite> key → sentence via a lookup dict, and publishes <cite>std_msgs/String</cite> on <cite>/voice_recogn</cite>.</p></li>
<li><p><strong>reasoning_order_verification.py</strong>
- Listens to <cite>/voice_recogn</cite>, checks for the fragment <strong>“Can I have”</strong> and valid dishes from a <cite>food_list</cite>.
- On success, publishes a structured <cite>tiago1/Voice_rec</cite> to <cite>/verif_T_manager</cite> and calls the <cite>send_order</cite> service; on failure, emits error codes (1 = no dish, 2 = missing phrase) on <cite>/error_from_interaction</cite>.</p></li>
<li><p><strong>speech_generator.py</strong>
- Buffers the latest text command from <cite>/task_speech_command</cite> and republishes it at 1 Hz on <cite>/speaker_channel</cite>, ensuring no more than one announcement per second.</p></li>
<li><p><strong>speaker.py</strong>
- Subscribes to <cite>/speaker_channel</cite> and immediately relays each <cite>std_msgs/String</cite> to <cite>/speaker_output</cite>, with latching so late‐joining TTS drivers still hear the last message.</p></li>
</ul>
</section>
<section id="ros-interfaces-kpis">
<h2>ROS interfaces &amp; KPIs<a class="headerlink" href="#ros-interfaces-kpis" title="Link to this heading"></a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 33.0%" />
<col style="width: 22.0%" />
<col style="width: 45.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Topic / Service</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>KPI / Note</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">/&lt;robot&gt;/mic_channel</span></code> ← <em>microphone.py</em></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">std_msgs/Int32</span></code></p></td>
<td><p>1 Hz, latency ≤ 100 ms</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">/voice_recogn</span></code> ← <em>voice_recognition.py</em></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">std_msgs/String</span></code></p></td>
<td><p>Word error rate ≤ 5 % on test set</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">/error_from_interaction</span></code> ← <em>reasoning_order_verification.py</em></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">std_msgs/Int32</span></code></p></td>
<td><p>Code 1 (no dish) &lt; 2 % of valid orders</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">/verif_T_manager</span></code> ← <em>reasoning_order_verification.py</em></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">tiago1/Voice_rec</span></code></p></td>
<td><p>Published ≤ 200 ms after utterance</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">/speaker_channel</span></code> ← <em>reasoning_speech_generation.py</em></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">std_msgs/String</span></code></p></td>
<td><p>One buffer slot, no drops</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">/speaker_output</span></code> ← <em>speaker.py</em></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">std_msgs/String</span></code></p></td>
<td><p>Latched; late TTS subscribers still get last sentence</p></td>
</tr>
</tbody>
</table>
</section>
<section id="implementation-modules">
<h2>Implementation modules<a class="headerlink" href="#implementation-modules" title="Link to this heading"></a></h2>
<p>Click any component for full API documentation.</p>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Interaction Components</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="interaction_modules/voice_recognition.html">Voice Recognition</a></li>
<li class="toctree-l1"><a class="reference internal" href="interaction_modules/microphone.html">Microphone</a></li>
<li class="toctree-l1"><a class="reference internal" href="interaction_modules/reasoning_order_verification.html">Reasoning Order Verification</a></li>
<li class="toctree-l1"><a class="reference internal" href="interaction_modules/speaker.html">Speaker</a></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="control_modules/force.html" class="btn btn-neutral float-left" title="Force Sensor" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="interaction_modules/voice_recognition.html" class="btn btn-neutral float-right" title="Voice Recognition" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Arian Tavousi.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>